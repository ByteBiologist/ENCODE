{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Operating Procedure (SOP) for Updating ENCODE Data Tracks in FILER\n",
    "## 1.Introduction\n",
    "* ``ENCODE (Encyclopedia of DNA Elements)`` data tracks in FILER are periodically updated. This SOP outlines the step-by-step process for systematically collecting, processing, and integrating newly released ENCODE data tracks into FILER.\n",
    "* For consistency, only bigBed files are downloaded from ENCODE and converted to BED format using <u>bigBedToBed.</u>\n",
    "### 1.1 Purpose\n",
    "The purpose of this SOP is to ensure consistency, accuracy, and efficiency in updating ENCODE data tracks within FILER.\n",
    "### 1.2 Revision History\n",
    "\n",
    "- **Version 1.0:** Initial draft version. 2024 Update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection\n",
    "### 2.1. bigBed Tracks from ENCODE\n",
    "To begin the update process, select all the bigBed tracks available in the ENCODE experiment matrix, using the below selection criteria:\n",
    "\n",
    "- Biosample: Organism --> Homo sapiens\n",
    "- Quality: Status --> released, archived, revoked\n",
    "- Analysis: Available file types --> All bigBed files\n",
    "- Analysis: Genome Assembly --> hg19, GRCh38\n",
    "\n",
    "The following URL is pre-selected to meet the above criteria on the ENCODE data portal:\n",
    "\n",
    "[ENCODE BigBed Files](https://www.encodeproject.org/search/?type=Experiment&control_type!=*&status=released&perturbed=false&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens&status=archived&status=revoked&files.file_type=bigBed+narrowPeak&files.file_type=bigBed+broadPeak&files.file_type=bigBed+bed3%2B&files.file_type=bigBed+bedRnaElements&files.file_type=bigBed+tss_peak&files.file_type=bigBed+bedMethyl&files.file_type=bigBed+bed9%2B&files.file_type=bigBed+idr_peak&files.file_type=bigBed+bed9&files.file_type=bigBed+bedLogR&files.file_type=bigBed+bed12&files.file_type=bigBed+bed6%2B&files.file_type=bigBed+bedExonScore&files.file_type=bigBed+peptideMapping&files.file_type=bigBed+bed3&files.file_type=bigBed+modPepMap&files.file_type=bigBed+pepMap)\n",
    "\n",
    "(Verify the selection: Ensure that all bigBed files are selected under `'Analysis - Available file types'`)\n",
    "\n",
    "#### 2.1.1 ENCODE File status\n",
    "\n",
    "On the ENCODE portal, statuses are used to indicate different processing phase.\n",
    "\n",
    "[ENCODE status terminology](https://www.encodeproject.org/help/getting-started/status-terms/#FileStatuses)\n",
    "\n",
    "- Released: These files have been been released to public.\n",
    "- Archived: These files are considered superfluous or outdated. There is nothing wrong with these files , but it is considered an extra to the experiment.\n",
    "- Revoked: These files were deemed erroneous or significantly below standards after it had been released. \n",
    "\n",
    "In FILER, we adhere to the same rules as ENCODE. We only include ENCODE files with 'Released' status.\n",
    "\n",
    "The status information for 'archived' and 'revoked' files are collected for downstream use, specifically for archiving these files from FILER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Download metadata\n",
    "Using the **ENCODE batch Download** option, get the `files.txt` file, which is a list of URLs to a file containing all the experimental metadata and links to download the file. \n",
    "The first line of the file has the URL or command line to download the metadata file.\n",
    "\n",
    "The following command will download the `metadata.tsv` file, which contains metadata describing the assay and the files for all the bigBed tracks.\n",
    "\n",
    "head -n 1 files.txt | xargs -n 1 curl -O -J -L\n",
    "\n",
    "[ENCODE Metadata schema](https://www.encodeproject.org/help/batch-download/) \n",
    "\n",
    "![Alt text](/mnt/ebs/jackal/FILER2/FILER2-production/ENCODE/ENCODE_batch_download.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Metadata filtering\n",
    "\n",
    "To identify newly released ENCODE tracks that are not yet added to FILER, compare the list of bigBed tracks using the `File accession` column from `metadata.tsv` with the existing ENCODE tracks in FILER.\n",
    "\n",
    "This generates a list of all bigBed files released since the last FILER update.\n",
    "\n",
    "#### Filtering Criteria\n",
    "\n",
    "Apply the following filtering criteria to refine the list of tracks to be updated:\n",
    "\n",
    "- **File Status:** Exclude tracks with `Archived` and `Revoked` file status.\n",
    "- **Output Type:** Exclude tracks in data output types `FDR cut rate` and `peaks and background as input for IDR`.\n",
    "- **File Format:** Exclude tracks in `bedMethyl` format.\n",
    "- **Assay:** Check for new assay types.\n",
    "\n",
    "These filtering criteria ensure that only relevant tracks are selected for further processing and integration into FILER. \n",
    "\n",
    "**Discussion with FILER Team**\n",
    "\n",
    "Discuss and finalize the filtering criteria during FILER team meeting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2024 update:\n",
    "\n",
    "The following assays are excluded after discussing their use cases in FILER:\n",
    "\n",
    "- BruChase-seq\n",
    "- Bru-seq\n",
    "- BruUV-seq\n",
    "- polyA minus RNA-seq\n",
    "- polyA plus RNA-seq\n",
    "- small RNA-seq\n",
    "- total RNA-seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. File download\n",
    "\n",
    "With the final list of bigBed files are ready, proceed to download using the `files.txt` obtained in section 2.2. Filter `files.txt` to extract only the URLs corresponding to the bigBed files using **file accession**\n",
    "\n",
    "To download the bigBed files, use the following command:\n",
    "\n",
    "xargs -L 1 curl -O -J -L < files.txt\n",
    "\n",
    "This command will download files listed in `filtered_bigBed_files.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metadata Collection\n",
    "\n",
    "Collect the following metadata from `metadata.tsv` for each track. This information will be used to construct FILER metadata:\n",
    "\n",
    "- File format\n",
    "- Output type\n",
    "- File assembly\n",
    "- Experiment accession\n",
    "- Assay\n",
    "- Biosample term id\n",
    "- Biosample term name\n",
    "- Biosample type\n",
    "- Experiment target\n",
    "- Biological replicate(s)\n",
    "- Technical replicate(s)\n",
    "- File download URL\n",
    "- Experiment date released\n",
    "- Project\n",
    "- File analysis title\n",
    "\n",
    "This metadata collection process ensures that all necessary information is gathered for each track, facilitating the construction of accurate and comprehensive metadata entries in FILER.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ENCODE metadata schema (2024)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "| File accession | File format | File type | File format type | Output type           | File assembly | Experiment accession | Assay       | Donor(s)                   | Biosample term id | Biosample term name | Biosample type | Biosample organism | Biosample treatments | Biosample treatments amount | Biosample treatments duration | Biosample genetic modifications methods | Biosample genetic modifications categories | Biosample genetic modifications targets                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | Biosample genetic modifications gene targets | Biosample genetic modifications site coordinates | Biosample genetic modifications zygosity | Experiment target | Library made from  | Library depleted in | Library extraction method | Library lysis method | Library crosslinking method | Library strand specific | Experiment date released | Project | RBNS protein concentration | Library fragmentation method | Library size range | Biological replicate(s) | Technical replicate(s) | Read length | Mapped read length | Run type | Paired end | Paired with | Index of | Derived from                                                 | Size   | Lab                        | md5sum                           | dbxrefs | File download URL                                                             | Genome annotation | Platform | Controlled by | File Status | s3_uri                                                                                | Azure URL                                                                                                                                                                                            | File analysis title   | File analysis status | Audit WARNING                                                         | Audit NOT_COMPLIANT | Audit ERROR |\n",
    "|----------------|-------------|-----------|------------------|-----------------------|---------------|----------------------|-------------|----------------------------|-------------------|---------------------|----------------|--------------------|----------------------|-----------------------------|-------------------------------|-----------------------------------------|--------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|--------------------------------------------------|------------------------------------------|-------------------|--------------------|---------------------|---------------------------|----------------------|-----------------------------|-------------------------|--------------------------|---------|----------------------------|------------------------------|--------------------|-------------------------|------------------------|-------------|--------------------|----------|------------|-------------|----------|--------------------------------------------------------------|--------|----------------------------|----------------------------------|---------|-------------------------------------------------------------------------------|-------------------|----------|---------------|-------------|---------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------|----------------------|-----------------------------------------------------------------------|---------------------|-------------|\n",
    "| ENCFF105HVH    | bed         | narrowPeak| bed              | IDR thresholded peaks | GRCh38        | ENCSR228ELU          | TF ChIP-seq | /human-donors/ENCDO000AAD/ | EFO:0002067       | K562                | cell line      | Homo sapiens       |                      |                             |                               | CRISPR                                  | insertion                                  | {'schema_version': '14', 'aliases': [], 'organism': {'schema_version': '6', '@type': ['Organism', 'Item'], 'name': 'human', 'taxon_id': '9606', 'scientific_name': 'Homo sapiens', '@id': '/organisms/human/', 'uuid': '7745b647-ff15-4ff3-9ced-b897d4e2983c', 'status': 'released'}, 'genes': ['/genes/7003/'], '@type': ['Target', 'Item'], 'name': 'TEAD1-human', 'label': 'TEAD1', '@id': '/targets/TEAD1-human/', 'title': 'TEAD1 (Homo sapiens)', 'investigated_as': ['transcription factor'], 'uuid': '8a929742-012b-441c-a1b0-3dfaa7d78ef7', 'status': 'released'} |                                              |                                                  |                                          | TEAD1-human       | DNA                |                     |                           |                      |formaldehyde                 |                         | 2022-01-13               | ENCODE  |                            | sonication (generic)         |                    | 2                       | 2_1                    |             |                    |          |            |             |          |/files/ENCFF604PVE/, /files/ENCFF872HPF/, /files/ENCFF356LFX/ | 238183 | ENCODE Processing Pipeline | add6b67d6290baeaa2158f6f6de00292 |         | https://www.encodeproject.org/files/ENCFF105HVH/@@download/ENCFF105HVH.bed.gz |                   |          |               | released    | s3://encode-public/2022/01/07/4ec8e455-0983-4697-9c24-8bff7cd2fa40/ENCFF105HVH.bed.gz | https://datasetencode.blob.core.windows.net/dataset/2022/01/07/4ec8e455-0983-4697-9c24-8bff7cd2fa40/ENCFF105HVH.bed.gz?sv=2019-10-10&si=prod&sr=c&sig=9qSQZo4ggrCNpybBExU8SypuUZV33igI11xw0P7rB3c%3D | ENCODE4 v1.8.0 GRCh38 | released             | mild to moderate bottlenecking, missing genetic modification reagents |                     |             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. JSON File Download\n",
    "\n",
    "These JSON files contain additional metadata that are not provided in `metadata.tsv`. They will be used to enrich the metadata collection for a comprehensive representation of each ENCODE track.\n",
    "\n",
    "### 4.1. Downloading JSON Files for BigBed Tracks\n",
    "\n",
    "For each bigBed track, download the corresponding JSON file by providing the `File accession` list as input to the following command:\n",
    "\n",
    "cat bigBed.track.list | parallel --jobs 12 'curl -L -H \"Accept: application/json\" https://www.encodeproject.org/files/{}/ > track/{}.json'\n",
    "\n",
    "This command uses parallel processing to efficiently download JSON files for multiple tracks simultaneously. Each JSON file contains metadata and additional information about the corresponding bigBed track.\n",
    "\n",
    "### 4.2. Downloading JSON Files for Experiments\n",
    "\n",
    "Additionally, download JSON files for experiments by providing the `Experiment accession` (from metadata.tsv) list as input to the following command:\n",
    "\n",
    "cat experiment.list | parallel --jobs 12 'curl -L -H \"Accept: application/json\" https://www.encodeproject.org/files/{}/ > experiment/{}.json'\n",
    "\n",
    "These files have experiment level metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Additional Metadata Collection\n",
    "\n",
    "### 5.1. Metadata Collection from Individual Tracks JSON\n",
    "\n",
    "Extract the following metadata records from bigBed track JSON files:\n",
    "\n",
    "- .date_created: `File release date.`\n",
    "- .submitted_file_name: `Original file name.`\n",
    "\n",
    "Use the script below to collect the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "Script to extract ENCODE bigBed track metadata from JSON files.\n",
    "\n",
    "Date_added in this refers to Individual track (bigBed files) release date; Release date column in FILER metadata.\n",
    "\n",
    "Json files are pre-downloaded.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "def extract_info(file):\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        submitted_file_name = data.get(\"submitted_file_name\", \"\")\n",
    "        name = os.path.basename(submitted_file_name)\n",
    "        date = data.get(\"date_created\", \"\").split(\"T\")[0]\n",
    "        return os.path.splitext(os.path.basename(file))[0], name, date\n",
    "\n",
    "def main(directory):\n",
    "    output_file = \"bigBed_track_metadata.txt\"\n",
    "    with open(output_file, 'w') as out_f:\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(directory, file)\n",
    "                file_base, name, date = extract_info(file_path)\n",
    "                out_f.write(f\"{file_base}\\tSubmitted_track_name={name}\\tRelease_date={date}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python script.py <directory>\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    directory = sys.argv[1]\n",
    "    main(directory)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "bigBed_track_metadata.txt\n",
    "\n",
    "ENCFF023GMW     Submitted_track_name=footprints.fps.0.01.bb     Release_date=2020-09-26\n",
    "ENCFF025IUF     Submitted_track_name=footprints.fps.0.01.bb     Release_date=2020-10-02\n",
    "ENCFF025TEX     Submitted_track_name=footprints.fps.0.01.bb     Release_date=2020-09-22\n",
    "ENCFF032CDC     Submitted_track_name=footprints.fps.0.01.bb     Release_date=2020-10-03\n",
    "ENCFF044NXH     Submitted_track_name=footprints.fps.0.01.bb     Release_date=2020-10-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Metadata Collection from Experiment JSON\n",
    "\n",
    "Extract the following metadata records from experiment JSON files:\n",
    "\n",
    "- .biosample_summary: `Biosample summary.`\n",
    "- .biosample_ontology: `System category.`\n",
    "- .lab: `Lab.`\n",
    "- .life_stage_age: `Life stage.`\n",
    "\n",
    "Use the script below to collect the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\"\"\"\n",
    "Script to extract ENCODE experiments metadata from JSON files.\n",
    "\n",
    "Json files are pre-downloaded.\n",
    "\n",
    "Use the 'Experiment accession' in the metadata to map Experiments to individual tracks\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "def extract_info(file):\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        lab = data.get(\"lab\", {}).get(\"title\", \"\")\n",
    "        bio = data.get(\"biosample_summary\", \"\")\n",
    "        system = \",\".join(data.get(\"biosample_ontology\", {}).get(\"system_slims\", []))\n",
    "        life_stage_ages = \",\".join([control.get(\"life_stage_age\", \"\") for control in data.get(\"possible_controls\", [])])\n",
    "        return lab, bio, system, life_stage_ages\n",
    "\n",
    "def main(directory):\n",
    "    output_file = \"experiment_metadata.txt\"\n",
    "    with open(output_file, 'w') as out_f:\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(directory, file)\n",
    "                lab, bio, system, life_stage_ages = extract_info(file_path)\n",
    "\n",
    "                # Process file name to remove extension\n",
    "                file_base = os.path.splitext(file)[0]\n",
    "\n",
    "                # Constructing key-value pairs for the second column\n",
    "                key_value_pairs = \"\"\n",
    "                if bio:\n",
    "                    key_value_pairs += f\"Biosample_summary={bio};\"\n",
    "                if lab:\n",
    "                    key_value_pairs += f\"Lab={lab};\"\n",
    "                if system:\n",
    "                    key_value_pairs += f\"System={system};\"\n",
    "\n",
    "                # Output key-value pairs if there's any non-empty value\n",
    "                if key_value_pairs or life_stage_ages:\n",
    "                    out_f.write(f\"{file_base}\\t{key_value_pairs}\\t{life_stage_ages}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python script.py <directory>\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    directory = sys.argv[1]\n",
    "    main(directory)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "experiment_metadata.txt\n",
    "\n",
    "ENCSR000AKE     Biosample_summary=Homo sapiens GM12878;Lab=Bradley Bernstein, Broad;System=immune system;\n",
    "ENCSR000AKP     Biosample_summary=Homo sapiens K562;Lab=Bradley Bernstein, Broad;System=immune system;  adult 53 years\n",
    "ENCSR000AKQ     Biosample_summary=Homo sapiens K562;Lab=Bradley Bernstein, Broad;System=immune system;  adult 53 years\n",
    "ENCSR000AKR     Biosample_summary=Homo sapiens K562;Lab=Bradley Bernstein, Broad;System=immune system;  adult 53 years\n",
    "ENCSR000AKS     Biosample_summary=Homo sapiens K562;Lab=Bradley Bernstein, Broad;System=immune system;  adult 53 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Organizing Collected Metadata for FILER\n",
    "\n",
    "Collected metadata are organized and stored in the following columns in FILER metadata:\n",
    "\n",
    "- **Biosample summary**: Extracted from experiment JSON files.\n",
    "- **Lab**: Extracted from experiment JSON files.\n",
    "- **System category**: Extracted from experiment JSON files.\n",
    "- **Original file name**: Extracted from individual track JSON files.\n",
    "- **Experiment date released**: Retrieved from ENCODE metadata.\n",
    "- **File analysis title**: Retrieved from ENCODE metadata.\n",
    "\n",
    "These metadata categories are stored as key-value pairs under the `Track Description` column in FILER metadata.\n",
    "\n",
    "Additionally, the following metadata categories are stored in specific columns:\n",
    "\n",
    "- **Life stage**: Stored under the `Life stage` column in FILER metadata.\n",
    "- **File release date**: Stored under the `Release date` column in FILER metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Removing Deprecated Files from FILER\n",
    "\n",
    "To ensure that FILER only contains the active files, the `file status` of each existing ENCODE tracks needs to be verified.\n",
    "\n",
    "### 6.1. Metadata Filtering\n",
    "\n",
    "Utilizing the `metadata.tsv` file downloaded in section 2.2, filter out new files to retain metadata only for existing FILER files. Check the `File status` column, filtering for archived and revoked tracks.\n",
    "\n",
    "The resulting final list of files needs to be removed from FILER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Processing\n",
    "\n",
    "The bigBed files downloaded in section 2.4 need to be processed into BED like (BED3+) format. \n",
    "\n",
    "\n",
    "### 7.1. Processing steps:\n",
    "\n",
    "1. Convert bigBed to BED format using `bigBedToBed` tool. Discard files with errors.\n",
    "2. Add headers to each track based on their file format. Some ENCODE data formats and their headers are as follows:\n",
    "\n",
    "    - **narrowPeak**: chrom;chromStart;chromEnd;name;score;strand;signalValue;pValue;qValue;peak\n",
    "    - **broadPeak**: chrom;chromStart;chromEnd;name;score;strand;signalValue;pValue;qValue\n",
    "    - **bed5**: chrom;chromStart;chromEnd;name;score\n",
    "    - **bedLogR**: chrom;chromStart;chromEnd;name;score;strand;thickStart;thickEnd;reserved;logR\n",
    "    - **bed6+2 miRNA**: chrom;chromStart;chromEnd;name;score;strand;miRNAname;expressionValue\n",
    "    \n",
    "    ### qValue/pValue based filtering - Future processing step!\n",
    "\n",
    "    If encountering a new data format, find the corresponding column names from ENCODE.\n",
    "\n",
    "3. Sort and compress the BED files.\n",
    "\n",
    "These processing steps ensure that the bigBed files are converted to the appropriate BED format and compressed for efficient storage and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quality Check (QC)\n",
    "\n",
    "### 8.1 Data quality\n",
    "\n",
    "Ensure data quality with the following steps:\n",
    "\n",
    "1. Check for empty files.\n",
    "2. Verify header and contents for each file format.\n",
    "\n",
    "These QC steps ensure the integrity and reliability of the processed data.\n",
    "\n",
    "### 8.2 Metadata QC\n",
    "\n",
    "The QC checks are to verify the accuracy and integrity of the metadata, confirming that it meets the required standards.\n",
    "\n",
    "Run the metadata QC pipeline after completing the FILER metadata generation.\n",
    "\n",
    "Below is the QC script which performs various quality control (QC) checks on the metadata. These checks include:\n",
    "\n",
    "- Verifying the correct end-of-line character expected on UNIX\n",
    "- Checking whether the header matches a predefined header\n",
    "- Evaluating Giggle indexes\n",
    "- Consistency of Giggle index and annotation files\n",
    "- Updating any life stages that need correction\n",
    "- Inspecting the metadata for any blank fields\n",
    "- Checking the URL download prefix matches the URL link\n",
    "- Verifying that fields have consistent capitalization patterns\n",
    "- Detecting and resolving any double slashes in fields\n",
    "- Ensuring the uniqueness of the Identifier field\n",
    "- Verifying the uniqueness of the Processed file md5 field\n",
    "- Checking that all rows have the correct number of fields\n",
    "- Verifying the accessibility and validity of provided Processed File URLs\n",
    "- Ensuring the correctness and matching of file sizes and md5sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "######################################################################\n",
    "# FILER Metadata Quality Check (QC) Pipeline\n",
    "######################################################################\n",
    "\n",
    "input_md=$1\n",
    "project_name=${2:-\"undefined\"}\n",
    "break_on_error=${3:-\"true\"}\n",
    "\n",
    "if [ $break_on_error == \"true\" ]; then\n",
    "    set -e\n",
    "fi\n",
    "\n",
    "if [ $project_name == \"undefined\" ]; then\n",
    "    project_name=$(basename $(dirname $input_md))\n",
    "fi\n",
    "\n",
    "md_name=\"/mnt/data/jeffrey/FILER/scripts/metadata/checking/${project_name}_master_project_metadata.tsv\"\n",
    "\n",
    "## Do a temporary version\n",
    "echo -e \"----------\\nSaving working version to ./checking:\"\n",
    "cp $input_md $md_name\n",
    "\n",
    "## Check for correct end-of-line character\n",
    "echo -e \"\\n----------\\nChecking whether provided metadata has the correct end-of-line character expected on UNIX:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_unix_eol.sh $md_name\n",
    "\n",
    "## Add a header\n",
    "echo -e \"----------\\nChecking whether header matches ./metadata_header.txt exactly:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_header.sh $md_name\n",
    "\n",
    "## Use check files\n",
    "echo -e \"\\n----------\\nRun check_files to evaluate Giggle indexes:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_files_alt.sh $md_name\n",
    "\n",
    "## Check file ages\n",
    "echo -e \"\\n----------\\nWhecking that giggle index is older than all contained files:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_file_ages.sh $md_name\n",
    "\n",
    "## Check the life stages\n",
    "echo -e \"\\n----------\\nChecking whether any life stages need to be fixed:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/update_life_stages.sh $md_name\n",
    "\n",
    "## Check for empty elements\n",
    "echo -e \"\\n----------\\nChecking to see if any fields are blank:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/inspect_metadata_for_empty.sh $md_name\n",
    "\n",
    "if [ 0 = 1 ]; then\n",
    "\n",
    "## Check for correct number of columns\n",
    "echo -e \"\\n----------\\nChecking to see if column number compatible with declared format:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_columns_alt.sh $md_name\n",
    "\n",
    "## Check output dirs\n",
    "echo -e \"\\n----------\\nChecking that each output dir only contains one output type:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_dirs_and_outputtypes_alt.sh $md_name\n",
    "\n",
    "fi\n",
    "\n",
    "## Check download prefixes\n",
    "echo -e \"\\n----------\\nChecking that URL download prefix matches URL link (will print if mismatch):\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_url_and_target_dir_match_alt.sh $md_name\n",
    "\n",
    "## Check for capitalization issues\n",
    "echo -e \"\\n----------\\nChecking whether any fields have varying capitalization patterns:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_capitalization_alt.sh $md_name\n",
    "\n",
    "## Check for double-slashes\n",
    "echo -e \"\\n----------\\nChecking whether any field has a double slash in it, ignoring https:// and http:// :\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/detect_double_slashes.sh $md_name\n",
    "\n",
    "## Check that Identifier is always unique\n",
    "echo -e \"\\n----------\\nChecking whether Identifier field is always unique:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_unique_identifiers.sh $md_name\n",
    "\n",
    "## Check that md5sum is always unique\n",
    "echo -e \"\\n----------\\nChecking whether Processed file md5 field is always unique:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_unique_md5.sh $md_name\n",
    "\n",
    "## Check that column number is always correct\n",
    "echo -e \"\\n----------\\nChecking whether all rows have the right number of fields:\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_cols_and_empty_rows.sh $md_name\n",
    "\n",
    "## Check download availability\n",
    "echo -e \"\\n----------\\nChecking whether provided Processed File URLS are actually accessible and valid\"\n",
    "python /mnt/data/jeffrey/FILER/scripts/metadata/check_download_links.py $md_name\n",
    "\n",
    "## Check sizes etc.\n",
    "echo -e \"\\n----------\\nChecking whether the file sizes and md5sums are correct/match expected.\"\n",
    "bash /mnt/data/jeffrey/FILER/scripts/metadata/check_md5_and_filesize.sh $md_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Organization and Indexing\n",
    "\n",
    "Organize the processed data following FILER's data structure guidelines. Ensure that the processed BED files are structured appropriately according to the specified directory hierarchy and naming conventions.\n",
    "\n",
    "After organization, index the processed BED files using [tabix](https://www.htslib.org/doc/tabix.html) and [giggle](https://github.com/ryanlayer/giggle). Indexing facilitates efficient data retrieval and querying, enhancing the accessibility and usability of the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Processed BED files\n",
    "\n",
    "Processed ENCODE data in FILER: \n",
    "\n",
    "**ENCFF569TJO.bed.gz**: TF-ChIP-seq, narrowpeak, hg38"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#chrom  chromStart      chromEnd        name    score   strand  signalValue     pValue  qValue  peak\n",
    "chr1    1780356 1780780 .       1000    .       33.02714        -1.00000        3.83904 212\n",
    "chr1    1996125 1996549 .       709     .       18.31664        -1.00000        3.83904 212\n",
    "chr1    2234495 2234919 .       1000    .       29.90587        -1.00000        3.83904 212\n",
    "chr1    3668792 3669216 .       574     .       16.16944        -1.00000        3.83904 212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENCFF002TMO.bed.gz**: DNase-seq, bed5, hg38"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#chrom  chromStart      chromEnd        name    FDR-footprints\n",
    "chr1    181420  181433  .       0.01\n",
    "chr1    181436  181453  .       0.01\n",
    "chr1    181478  181506  .       0.01\n",
    "chr1    181531  181558  .       0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. FILER metadata"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "| Identifier | Data Source | File name          | Number of intervals | bp covered | Output type           | Genome build | Cell type | Biosample type | Biosamples term id | Tissue category | ENCODE Experiment id | Biological replicate(s) | Technical replicate | Antibody       | Assay       | File format    | File size | Filepath                                                                            | Downloaded date | Release date | Date added to FILER | Processed File Download URL | Processed file md5               | wget command | tabix_index Download | Link out URL                  | Raw File URL | Raw file download | Raw file md5                     | Data Category | classification                    | Track Description                                                                                                                                                                                                                                                                                                                                    | system category | life stage |\n",
    "|------------|-------------|--------------------|---------------------|------------|-----------------------|--------------|-----------|----------------|--------------------|-----------------|----------------------|-------------------------|---------------------|----------------|-------------|----------------|-----------|-------------------------------------------------------------------------------------|-----------------|--------------|---------------------|-----------------------------|----------------------------------|--------------|----------------------|-------------------------------|--------------|-------------------|----------------------------------|---------------|-----------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------|------------|\n",
    "| NGEN064154 | ENCODE      | ENCFF569TJO.bed.gz | 3105                | 1303692    | IDR thresholded peaks | hg38         | BLaER1    | Cell line      | EFO:0030018        | Not applicable  | ENCSR236DYB          | 2                       | 2_1                 | Cebpa          | TF ChIP-seq | bed narrowPeak | 52396     | /project/wang4/FILER/Annotationtracks/ENCODE/data/TF-ChIP-seq/narrowpeak/hg38/3      | 5/15/24         | 2/12/23      | 5/25/24             | Processed File Download URL | a7fc28287e7740c64165c422aab71a0c | wget command | tabix_index Download | https://www.encodeproject.org | Raw File URL | Raw file download | a3e73903524074e082861a2b0fcbaa06 | Called peaks  | TF ChIP-seq IDR thresholded peaks | Biosample_summary=BLaER1 72 hours after the sample was treated with 100 nM 17β-estradiol, 10 ng/mL Interleukin-3, 10 ng/mL CSF1; Lab=Roderic Guigo, CRG; System=skeletal system,immune system; Submitted_track_name=rep2-pr1_vs_rep2-pr2.idr0.05.bfilt.regionPeak.bb; Experiment_date_released=05/10/2022; File_analysis_title=ENCODE4 v1.8.1 GRCh38 | Not applicable  | Unknown    |\n",
    "| NGEN038559 | ENCODE      | ENCFF002TMO.bed.gz | 612320              | 7708578    | footprints            | hg38         | Kidney    | Tissue         | UBERON:0002113     | Kidney          | ENCSR792ZXA          | 2                       | 2_1                 | Not applicable | DNase-seq   | bed bed5       | 4090182   | /project/wang4/FILER/Annotationtracks/ENCODE/data/DNase-seq/bed5-FDR_footprints/hg38 | 6/12/22         | 10/24/20     | 11/20/22            | Processed File Download URL | 47d12d4dbe5240d0e4a85640e5b7aeb6 | wget command | tabix_index Download | https://www.encodeproject.org | Raw File URL | Raw file download | abee81cc3071d228ac9a21a04aee6891 | Called peaks  | DNase-seq footprints              | Biosample_summary=Kidney tissue embryo (59 days) and female embryo (59 days);Lab=John Stamatoyannopoulos, UW;System=excretory system;Submitted_track_name=footprints.fps.0.01.bb;Experiment_date_released=12/13/2017;File_analysis_title=ENCODE4 v3.0.0-alpha.2 GRCh38                                                                               | Renal\t        | Embryonic  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Validate FILER metadata\n",
    "\n",
    "Verify if the ENCODE metadata is updated for existing FILER ENCODE files. ENCODE may update and/or add more metadata for their files. This involves checking the metadata for files that have already been processed and incorporated into FILER.\n",
    "\n",
    "Use the downloaded JSON files to compare and ensure the metadata aligns with the current ENCODE standards. This validation ensures that all previously processed ENCODE files maintain consistency with the latest metadata updates from ENCODE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a step for cell type mapping, Refer cell-type tisse dictionary and the mapping script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
